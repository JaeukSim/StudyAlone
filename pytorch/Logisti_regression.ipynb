{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "import torch.optim as optim\r\n",
    "\r\n",
    "torch.manual_seed(1)\r\n",
    "# data\r\n",
    "x_data = [[1,2], [2,3], [3,1], [4,3],[5,3],[6,2]]\r\n",
    "y_data = [[0],[0],[0],[1],[1],[1]]\r\n",
    "\r\n",
    "# data -> tensor\r\n",
    "x_train = torch.FloatTensor(x_data)\r\n",
    "y_train = torch.FloatTensor(y_data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# class\r\n",
    "class BinaryClassifier(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super().__init__()\r\n",
    "        self.linear = nn.Linear(2,1) # input dim 2 output dim 1\r\n",
    "        self.sigmoid = nn.Sigmoid() # output -> sigmoid\r\n",
    "\r\n",
    "    def forward(self,x):\r\n",
    "        return self.sigmoid(self.linear(x))\r\n",
    "        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Model 선언\r\n",
    "model = BinaryClassifier()\r\n",
    "\r\n",
    "# optimizer \r\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\r\n",
    "\r\n",
    "# epoch 설정\r\n",
    "epoch_number = 300\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "print(model)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "BinaryClassifier(\n",
      "  (linear): Linear(in_features=2, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# Train Loop\r\n",
    "\r\n",
    "for epoch in range(epoch_number+1):\r\n",
    "    # H(x) 계산\r\n",
    "    hypothesis = model(x_train)\r\n",
    "\r\n",
    "    # loss\r\n",
    "    loss = F.binary_cross_entropy(hypothesis, y_train)\r\n",
    "\r\n",
    "    # loss H(x) 개선\r\n",
    "    optimizer.zero_grad()\r\n",
    "    loss.backward()\r\n",
    "    optimizer.step()\r\n",
    "    \r\n",
    "    #print 문 만들기\r\n",
    "    if epoch % 10 ==0:\r\n",
    "        prediction = hypothesis >= torch.FloatTensor([0.5])\r\n",
    "        correct_prediction = prediction.float() == y_train\r\n",
    "        acc = correct_prediction.sum().item() / len(correct_prediction)\r\n",
    "        print(\"Epoch : {:4d}/{} loss : {:.6f} Acc {:2.2f}%\".format(epoch, epoch_number, loss, acc))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch :    0/300 loss : 0.614994 Acc 0.67%\n",
      "Epoch :   10/300 loss : 0.559069 Acc 0.83%\n",
      "Epoch :   20/300 loss : 0.541587 Acc 0.83%\n",
      "Epoch :   30/300 loss : 0.526862 Acc 0.83%\n",
      "Epoch :   40/300 loss : 0.514000 Acc 0.83%\n",
      "Epoch :   50/300 loss : 0.502443 Acc 0.83%\n",
      "Epoch :   60/300 loss : 0.491833 Acc 0.83%\n",
      "Epoch :   70/300 loss : 0.481934 Acc 0.83%\n",
      "Epoch :   80/300 loss : 0.472587 Acc 0.83%\n",
      "Epoch :   90/300 loss : 0.463683 Acc 0.83%\n",
      "Epoch :  100/300 loss : 0.455148 Acc 0.83%\n",
      "Epoch :  110/300 loss : 0.446927 Acc 0.83%\n",
      "Epoch :  120/300 loss : 0.438981 Acc 0.83%\n",
      "Epoch :  130/300 loss : 0.431283 Acc 0.83%\n",
      "Epoch :  140/300 loss : 0.423811 Acc 0.83%\n",
      "Epoch :  150/300 loss : 0.416548 Acc 0.83%\n",
      "Epoch :  160/300 loss : 0.409482 Acc 0.83%\n",
      "Epoch :  170/300 loss : 0.402603 Acc 0.83%\n",
      "Epoch :  180/300 loss : 0.395903 Acc 0.83%\n",
      "Epoch :  190/300 loss : 0.389375 Acc 0.83%\n",
      "Epoch :  200/300 loss : 0.383012 Acc 0.83%\n",
      "Epoch :  210/300 loss : 0.376810 Acc 0.83%\n",
      "Epoch :  220/300 loss : 0.370763 Acc 0.83%\n",
      "Epoch :  230/300 loss : 0.364867 Acc 0.83%\n",
      "Epoch :  240/300 loss : 0.359117 Acc 0.83%\n",
      "Epoch :  250/300 loss : 0.353511 Acc 0.83%\n",
      "Epoch :  260/300 loss : 0.348043 Acc 0.83%\n",
      "Epoch :  270/300 loss : 0.342710 Acc 0.83%\n",
      "Epoch :  280/300 loss : 0.337508 Acc 0.83%\n",
      "Epoch :  290/300 loss : 0.332434 Acc 0.83%\n",
      "Epoch :  300/300 loss : 0.327485 Acc 0.83%\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}