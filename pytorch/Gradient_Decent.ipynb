{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "import torch.optim as optim"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# 현재 실습하고 있는 파이썬 코드 재실행 해도 다음에도 같은 결과가 나오도록 랜덤시드 설정\r\n",
    "torch.manual_seed(7777)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1c465c1bdf0>"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 실습을 위한 기본세팅 작업\r\n",
    "## 훈련데이터 X_train, y_train"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# 훈련데이터 X_train, y_train\r\n",
    "x_train = torch.FloatTensor(([1],[2],[3]))\r\n",
    "y_train = torch.FloatTensor(([2],[4],[6]))\r\n",
    "\r\n",
    "# x_train shape show\r\n",
    "print(\"x_train >>\", x_train.shape) #shape or size() 를 통해서 텐서의 형태를 볼 수 있다\r\n",
    "print(\"y_train >>\", y_train.size())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "x_train >> torch.Size([1, 3, 1])\n",
      "y_train >> torch.Size([3, 1])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# 가중치와 편향의 초기화\r\n",
    "# 가중치 0으로 초기화하고 이값을 출력, 편향 b도 0으로 초기화( 가중치는 기울기 편향은 y절편)\r\n",
    "# requires_grad = True -> 학습을 통해서 계속 값이 변경되는 변수입니다.\r\n",
    "w = torch.zeros(1, requires_grad=True)\r\n",
    "print(\"가중치 w : \", w)\r\n",
    "b = torch.zeros(1, requires_grad=True)\r\n",
    "print(\"편향 b : \", b)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "가중치 w :  tensor([0.], requires_grad=True)\n",
      "편향 b :  tensor([0.], requires_grad=True)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# 가설 선언\r\n",
    "# 파이토치 코드 상으로 직선의 방정식에 해당되는 가설을 선언\r\n",
    "\r\n",
    "hypothesis = x_train*w + b\r\n",
    "print(\"가설(hypothesis) : \", hypothesis)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "가설(hypothesis) :  tensor([[[0.],\n",
      "         [0.],\n",
      "         [0.]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Loss function 선언\r\n",
    "loss = torch.mean((hypothesis - y_train)**2)\r\n",
    "print(\"loss : \",loss)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loss :  tensor(18.6667, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# 경사 하강법 구현\r\n",
    "# input w b rk sgd 입력이 되어야 합니다.\r\n",
    "\r\n",
    "optimizer = optim.SGD([w,b], lr = 0.01)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# 기울기 0 초기화\r\n",
    "optimizer.zero_grad()\r\n",
    "\r\n",
    "# Loss function을 미분하여 기울기 계산\r\n",
    "loss.backward()\r\n",
    "\r\n",
    "# w와 b 값을 업데이트\r\n",
    "optimizer.step()\r\n",
    "\r\n",
    "# 학습을 진행\r\n",
    "epoch_num = 2000  # 원하는 만큼 경사 하강법을 반복"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# train mode 를 구성하기\r\n",
    "# epoch -> 전체훈련 데이터가 학습에 한번 사용되는 주기\r\n",
    "for epoch in range(0, epoch_num+1):\r\n",
    "    \r\n",
    "    # 가설 계산\r\n",
    "    hypothesis = x_train*w + b\r\n",
    "\r\n",
    "    # CNN 을 사용한다면....\r\n",
    "    # out = model(input)\r\n",
    "\r\n",
    "    # loss 계산\r\n",
    "    loss = torch.mean((hypothesis - y_train )**2)\r\n",
    "\r\n",
    "    # loss \r\n",
    "    optimizer.zero_grad() #0으로 셋팅\r\n",
    "    loss.backward() ## Loss function을 미분하여 기울기 계산\r\n",
    "    optimizer.step() # w와 b 값을 업데이트\r\n",
    "\r\n",
    "    #100번 마다 print\r\n",
    "    if epoch % 100 ==0:\r\n",
    "        print(\"Epoch {:4d}/{} w : {:.3f}, b :{:.3f} loss : {:.6f}\"\r\n",
    "        .format(epoch, epoch_num, w.item(), b.item(), loss.item()))\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch    0/2000 w : 0.353, b :0.151 loss : 14.770963\n",
      "Epoch  100/2000 w : 1.746, b :0.577 loss : 0.047939\n",
      "Epoch  200/2000 w : 1.801, b :0.453 loss : 0.029624\n",
      "Epoch  300/2000 w : 1.843, b :0.356 loss : 0.018306\n",
      "Epoch  400/2000 w : 1.877, b :0.280 loss : 0.011312\n",
      "Epoch  500/2000 w : 1.903, b :0.220 loss : 0.006990\n",
      "Epoch  600/2000 w : 1.924, b :0.173 loss : 0.004319\n",
      "Epoch  700/2000 w : 1.940, b :0.136 loss : 0.002669\n",
      "Epoch  800/2000 w : 1.953, b :0.107 loss : 0.001649\n",
      "Epoch  900/2000 w : 1.963, b :0.084 loss : 0.001019\n",
      "Epoch 1000/2000 w : 1.971, b :0.066 loss : 0.000630\n",
      "Epoch 1100/2000 w : 1.977, b :0.052 loss : 0.000389\n",
      "Epoch 1200/2000 w : 1.982, b :0.041 loss : 0.000240\n",
      "Epoch 1300/2000 w : 1.986, b :0.032 loss : 0.000149\n",
      "Epoch 1400/2000 w : 1.989, b :0.025 loss : 0.000092\n",
      "Epoch 1500/2000 w : 1.991, b :0.020 loss : 0.000057\n",
      "Epoch 1600/2000 w : 1.993, b :0.016 loss : 0.000035\n",
      "Epoch 1700/2000 w : 1.995, b :0.012 loss : 0.000022\n",
      "Epoch 1800/2000 w : 1.996, b :0.010 loss : 0.000013\n",
      "Epoch 1900/2000 w : 1.997, b :0.008 loss : 0.000008\n",
      "Epoch 2000/2000 w : 1.997, b :0.006 loss : 0.000005\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}